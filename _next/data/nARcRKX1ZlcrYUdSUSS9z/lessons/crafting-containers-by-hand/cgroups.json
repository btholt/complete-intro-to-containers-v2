{"pageProps":{"post":{"attributes":{"title":"cgroups","description":"In the Frontend Masters course \"Complete Intro to Containers\" taught by Brian Holt, participants learn how to manage server resources on high-traffic shopping days like Black Friday. The course introduces cgroups, a technology developed by Google, which safeguards sites from crashes by limiting resource usage per process, ensuring stability and preventing malicious overloads. This essential tool enhances server efficiency and security in shared environments, enabling robust e-commerce operations.","keywords":["Frontend Masters Containers","Brian Holt Containers Course","cgroups technology","server resource management","prevent server crashes","e-commerce server stability","Google cgroups implementation"]},"html":"<p>Okay, so now we&#39;ve hidden the processes from Eve so Bob and Alice can engage in commerce in privacy and peace. So we&#39;re all good, right? They can no longer mess with each other, right? Not quite. We&#39;re almost there.</p>\n<p>So now, say it&#39;s Black Friday, Boxing Day or Singles&#39; Day (three of the biggest shopping days in the year, pick the one that makes the most sense to you ðŸ˜„) and Bob and Alice are gearing up for their biggest sales day of the year. Everything is ready to go and at 9:00AM their site suddenly goes down without warning. What happened!? They log on to their chroot&#39;d, unshare&#39;d shell on your server and see that the CPU is pegged at 100% and there&#39;s no more memory available to allocate! Oh no! What happened?</p>\n<p>The first explanation could be that Eve has her site running on another virtual server and simply logged on and ran a malicious script that ate up all the available resources for Bob and Alice so that their sites would go down and Eve would be the only site that was up, increasing her sales.</p>\n<p>However, another (possibly more likely) explanation is that both Bob&#39;s and Alice&#39;s sites got busy at the same time and that in and of itself took all the resources without any malice involved, taking down their sites and everyone else&#39;s on the server. Or perhaps Bob&#39;s site had a memory leak and that was enough to take all the resources available.</p>\n<p>Suffice it to say, we still have a problem. Every isolated environment has access to all <em>physical</em> resources of the server. There&#39;s no isolation of physical components from these environments.</p>\n<p>Enter the hero of this story: cgroups, or control groups. Google saw this same problem when building their own infrastructure and wanted to protect runaway processes from taking down entire servers and made this idea of cgroups, so you can say &quot;this isolated environment only gets so much CPU, so much memory, etc. and once it&#39;s out of those it&#39;s out-of-luck, it won&#39;t get any more.&quot;</p>\n<p>This is a bit more difficult to accomplish but let&#39;s go ahead and give it a shot.</p>\n<blockquote>\n<p>cgroups v2 is now the standard. Run <code>grep -c cgroup /proc/mounts</code> in your terminal. If the number that is <strong>greater than one</strong>, the system you&#39;re using is cgroups v1. <a href=\"https://medium.com/@charles.vissol/cgroup-v2-in-details-8c138088f9ba#aa07\">Click here</a> if you want to try to get your system from cgroup v1 to v2. As this is fairly involved, I would just suggest using a more recent version of Ubuntu, as it will have cgroups v2 on it.</p>\n<p>If you want to learn cgroups v1 (which I would not suggest, as they&#39;re getting phased out), <a href=\"https://btholt.github.io/complete-intro-to-containers/cgroups\">the first version of this course</a> teaches them.</p>\n</blockquote>\n<p>cgroups, as we have said, allow you to move processes and their children into groups which then allow you to limit various aspects of them. Imagine you&#39;re running a single physical server for Google with both Maps and GMail having virtual servers on it. If Maps ships an infinite loop bug and it pins the CPU usage of the server to 100%, you only want Maps to go down and <em>not</em> GMail just because it happens to be colocated with Maps. Let&#39;s see how to do that.</p>\n<p>You interact with cgroups by a pseudo-file system. Honestly, the whole interface feels weird to me but that is what it is! Inside your #2 terminal (the non-unshared one) run <code>cd /sys/fs/cgroup</code> and then run <code>ls</code>. You&#39;ll see a bunch of &quot;files&quot; that look like <code>cpu.max</code>, <code>cgroup.procs</code>, and <code>memory.high</code>. Each one of these represents a setting that you can play with with regard to the cgroup. In this case, we are looking at the root cgroup: all cgroups will be children of this root cgroup. The way you make your own cgroup is by creating a folder inside of the cgroup.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># creates the cgroup</span>\n<span class=\"hljs-built_in\">mkdir</span> /sys/fs/cgroup/sandbox\n\n<span class=\"hljs-comment\"># look at all the files created automatically</span>\n<span class=\"hljs-built_in\">ls</span> /sys/fs/cgroup/sandbox\n</code></pre><p>We now have a sandbox cgroup, which is a child of the root cgroup and can put limits on it! If we wanted to create a child of sandbox, as you may have guessed, just create another folder inside of sandbox.</p>\n<p>Let&#39;s move our unshared environment into the cgroup. Every process belongs to exactly one cgroup. If you move a process to a cgroup, it will automatically be removed from the cgroup it was in. If we move our unshared bash process from the root cgroup to the sandbox cgroup, it will be removed from the root cgroup without you doing anything.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># Find your isolated bash PID, it&#x27;s the bash one immediately after the unshare</span>\nps aux\n\n<span class=\"hljs-comment\"># should see the process in the root cgroup</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.procs\n\n<span class=\"hljs-comment\"># puts the unshared env into the cgroup called sandbox</span>\n<span class=\"hljs-built_in\">echo</span> &lt;PID&gt; &gt; /sys/fs/cgroup/sandbox/cgroup.procs\n\n<span class=\"hljs-comment\"># should see the process in the sandbox cgroup</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/cgroup.procs\n\n<span class=\"hljs-comment\"># should see the process no longer in the root cgroup - processes belong to exactly 1 cgroup</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.proc\n</code></pre><p>We now have moved our unshared bash process into a cgroup. We haven&#39;t placed any limits on it yet but it&#39;s there, ready to be managed. We have a minor problem at the moment though that we need to solve.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># should see all the available controllers</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.controllers\n\n<span class=\"hljs-comment\"># there&#x27;s no controllers</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/cgroup.controllers\n\n<span class=\"hljs-comment\"># there&#x27;s no controllers enabled its children</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.subtree_control\n</code></pre><p>You have to enable controllers for the children and none of them are enabled at the moment. You can see the root cgroup has them all enabled, but hasn&#39;t enabled them in its subtree_control so thus none are available in sandbox&#39;s controllers. Easy, right? We just add them to subtree_control, right? Yes, but one problem: you can&#39;t add new subtree_control configs while the cgroup itself has processes in it. So we&#39;re going to create another cgroup, add the rest of the processes to that one, and then enable the subtree_control configs for the root cgroup.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># make new cgroup for the rest of the processes, you can&#x27;t modify cgroups that have processes and by default Docker doesn&#x27;t include any subtree_controllers</span>\n<span class=\"hljs-built_in\">mkdir</span> /sys/fs/cgroup/other-procs\n\n<span class=\"hljs-comment\"># see all the processes you need to move, rerun each time after you add as it may move multiple processes at once due to some being parent / child</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.procs\n\n<span class=\"hljs-comment\"># you have to do this one at a time for each process</span>\n<span class=\"hljs-built_in\">echo</span> &lt;PID&gt; &gt; /sys/fs/cgroup/other-procs/cgroup.procs\n\n<span class=\"hljs-comment\"># verify all the processes have been moved</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/cgroup.procs\n\n<span class=\"hljs-comment\"># add the controllers</span>\n<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;+cpuset +cpu +io +memory +hugetlb +pids +rdma&quot;</span> &gt; /sys/fs/cgroup/cgroup.subtree_control\n\n<span class=\"hljs-comment\"># notice how few files there are</span>\n<span class=\"hljs-built_in\">ls</span> /sys/fs/cgroup/sandbox\n\n<span class=\"hljs-comment\"># all the controllers now available</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/cgroup.controllers\n\n<span class=\"hljs-comment\"># notice how many more files there are now</span>\n<span class=\"hljs-built_in\">ls</span> /sys/fs/cgroup/sandbox\n</code></pre><p>We did it! We went ahead and added all the possible controllers, but normally you should add just the ones you need. If you want to learn more about what each of them does, <a href=\"https://docs.kernel.org/admin-guide/cgroup-v2.html#controllers\">the kernel docs are quite readable</a>.</p>\n<p>Let&#39;s get a third terminal going. From your host OS (Windows or macOS or your own Linux distro, not within Docker) run another <code>docker exec -it docker-host bash</code>. That way, we can have #1 inside the unshared environment, #2 running our commands, and #3 giving us a visual display of what&#39;s going with <code>htop</code>, a visual tool for seeing what process, CPU cores, and memory are doing.</p>\n<p>So, let&#39;s do three little exercises to demonstrate what we can do with a cgroup. First, let&#39;s make it so the unshared environment only has access to 80MB of memory instead of all of it.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># a cool visual representation of CPU and RAM being used</span>\napt-get install htop\n\n<span class=\"hljs-comment\"># from #3 so we can watch what&#x27;s happening</span>\nhtop\n\n<span class=\"hljs-comment\"># run this from #1 terminal and watch it in htop to see it consume about a gig of RAM and 100% of CPU core</span>\n<span class=\"hljs-built_in\">yes</span> | <span class=\"hljs-built_in\">tr</span> \\\\n x | <span class=\"hljs-built_in\">head</span> -c 1048576000 | grep n\n\n<span class=\"hljs-comment\"># from #2, (you can get the PID from htop) to stop the CPU from being pegged and memory from being consumed</span>\n<span class=\"hljs-built_in\">kill</span> -9 &lt;PID of <span class=\"hljs-built_in\">yes</span>&gt;\n\n<span class=\"hljs-comment\"># should see max, so the memory is unlimited</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/memory.max\n\n<span class=\"hljs-comment\"># set the limit to 80MB of RAM (the number is 80MB in bytes)</span>\n<span class=\"hljs-built_in\">echo</span> 83886080 &gt; /sys/fs/cgroup/sandbox/memory.max\n\n<span class=\"hljs-comment\"># from inside #1, see it limit the RAM taken up; because the RAM is limited, the CPU usage is limited</span>\n<span class=\"hljs-built_in\">yes</span> | <span class=\"hljs-built_in\">tr</span> \\\\n x | <span class=\"hljs-built_in\">head</span> -c 1048576000 | grep n\n</code></pre><p>I think this is very cool. We just made it so our unshared environment only has access to 80MB of RAM, so despite a script being run to literally just consume RAM, it was limited to only consuming 80MB of it.</p>\n<p>However, as you saw, the user inside of the container could still peg the CPU if they wanted to. Let&#39;s fix that. Let&#39;s only give them 5% of a core.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># inside #1 / the cgroup/unshare â€“ this will peg one core of a CPU at 100% of the resources available, see it peg 1 CPU</span>\n<span class=\"hljs-built_in\">yes</span> &gt; /dev/null\n\n<span class=\"hljs-comment\"># from #2, (you can get the PID from htop) to stop the CPU from being pegged</span>\n<span class=\"hljs-built_in\">kill</span> -9 &lt;PID of <span class=\"hljs-built_in\">yes</span>&gt;\n\n<span class=\"hljs-comment\"># from #2 this allows the cgroup to only use 5% of a CPU</span>\n<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&#x27;5000 100000&#x27;</span> &gt; /sys/fs/cgroup/sandbox/cpu.max\n\n<span class=\"hljs-comment\"># inside #1 / the cgroup/unshare â€“ this will peg one core of a CPU at 5% since we limited it</span>\n<span class=\"hljs-built_in\">yes</span> &gt; /dev/null\n\n<span class=\"hljs-comment\"># from #2, to stop the CPU from being pegged, get the PID from htop</span>\n<span class=\"hljs-built_in\">kill</span> -9 &lt;PID of <span class=\"hljs-built_in\">yes</span>&gt;\n</code></pre><p>Pretty cool, right? Now, no matter how bad the code is we run inside of our chroot&#39;d, unshare&#39;d, cgroup&#39;d environment, we cannot take more than 5% of a CPU core.</p>\n<p>One more demo, the dreaded <a href=\"https://en.wikipedia.org/wiki/Fork_bomb\">fork bomb</a>. A fork bomb is a script that forks itself into multiple processes, which then fork themselves, which then fork themselves, etc., until all resources are consumed and it crashes the computer. It can be written plainly as</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-function\"><span class=\"hljs-title\">fork</span></span>() {\n    fork | fork &amp;\n}\nfork\n</code></pre><p>but you&#39;ll see it written as <code>:(){ :|:&amp; };:</code> where <code>:</code> is the name of the function instead of <code>fork</code>.</p>\n<p>So someone could run a fork bomb on our system right now and it&#39;d limit the blast radius of CPU and RAM but creating and destroying so many processes still carries a toll on the system. What we can do to more fully prevent a fork bomb is limit how many PIDs can be active at once. Let&#39;s try that.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># See how many processes the cgroup has at the moment</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/pids.current\n\n<span class=\"hljs-comment\"># See how many processes the cgroup can create before being limited (max)</span>\n<span class=\"hljs-built_in\">cat</span> /sys/fs/cgroup/sandbox/pids.max\n\n<span class=\"hljs-comment\"># set a limit that the cgroup can only run 3 processes at a time</span>\n<span class=\"hljs-built_in\">echo</span> 3 &gt; /sys/fs/cgroup/sandbox/pids.max\n\n<span class=\"hljs-comment\"># this runs 5 15 second processes that run and then stop. run this from within #2 and watch it work. now run it in #1 and watch it not be able to. it will have to retry several times</span>\n<span class=\"hljs-keyword\">for</span> a <span class=\"hljs-keyword\">in</span> $(<span class=\"hljs-built_in\">seq</span> 1 5); <span class=\"hljs-keyword\">do</span> <span class=\"hljs-built_in\">sleep</span> 15 &amp; <span class=\"hljs-keyword\">done</span>\n\n<span class=\"hljs-comment\"># DO NOT RUN THIS ON YOUR COMPUTER. This is a fork bomb. If not accounted for, this would bring down your computer. However we can safely run inside our #1 because we&#x27;ve limited the amount of PIDs available. It will end up spawning about 100 processes total but eventually will run out of forks to fork.</span>\n:(){ :|:&amp; };:\n</code></pre><p>Attack prevented! 3 processes is way too few for anyone to do anything meaningful, but by limiting the max PIDs available it allows you to limit what damage could be done. I&#39;ll be honest, this is the first time I&#39;ve run a fork bomb on a computer and it&#39;s pretty exhilirating. I felt like I was in the movie <em>Hackers</em>. <a href=\"https://youtu.be/Rn2cf_wJ4f4\">Hack the planet!</a>.</p>\n<p>And now we can call this a container. You have handcrafted a container. A container is literally nothing more than what we did together. There are other sorts of technologies that will accompany containers, like runtimes and daeomons, but the containers themselves are just a combination of chroot, namespaces, and cgroups! Using these features together, we allow Bob, Alice, and Eve to run whatever code they want and the only people they can mess with is themselves.</p>\n<p>So while this is a container at its most basic sense, we haven&#39;t broached more advance topics like networking, deploying, bundling, or anything else that something like Docker takes care of for us. But now you know at its most base level what a container is, what it does, and how you <em>could</em> do this yourself, but you&#39;ll be grateful that Docker does it for you. On to the next lesson!</p>\n","markdown":"\nOkay, so now we've hidden the processes from Eve so Bob and Alice can engage in commerce in privacy and peace. So we're all good, right? They can no longer mess with each other, right? Not quite. We're almost there.\n\nSo now, say it's Black Friday, Boxing Day or Singles' Day (three of the biggest shopping days in the year, pick the one that makes the most sense to you ðŸ˜„) and Bob and Alice are gearing up for their biggest sales day of the year. Everything is ready to go and at 9:00AM their site suddenly goes down without warning. What happened!? They log on to their chroot'd, unshare'd shell on your server and see that the CPU is pegged at 100% and there's no more memory available to allocate! Oh no! What happened?\n\nThe first explanation could be that Eve has her site running on another virtual server and simply logged on and ran a malicious script that ate up all the available resources for Bob and Alice so that their sites would go down and Eve would be the only site that was up, increasing her sales.\n\nHowever, another (possibly more likely) explanation is that both Bob's and Alice's sites got busy at the same time and that in and of itself took all the resources without any malice involved, taking down their sites and everyone else's on the server. Or perhaps Bob's site had a memory leak and that was enough to take all the resources available.\n\nSuffice it to say, we still have a problem. Every isolated environment has access to all _physical_ resources of the server. There's no isolation of physical components from these environments.\n\nEnter the hero of this story: cgroups, or control groups. Google saw this same problem when building their own infrastructure and wanted to protect runaway processes from taking down entire servers and made this idea of cgroups, so you can say \"this isolated environment only gets so much CPU, so much memory, etc. and once it's out of those it's out-of-luck, it won't get any more.\"\n\nThis is a bit more difficult to accomplish but let's go ahead and give it a shot.\n\n> cgroups v2 is now the standard. Run `grep -c cgroup /proc/mounts` in your terminal. If the number that is **greater than one**, the system you're using is cgroups v1. [Click here][move-to-v2] if you want to try to get your system from cgroup v1 to v2. As this is fairly involved, I would just suggest using a more recent version of Ubuntu, as it will have cgroups v2 on it.\n>\n> If you want to learn cgroups v1 (which I would not suggest, as they're getting phased out), [the first version of this course][v1] teaches them.\n\ncgroups, as we have said, allow you to move processes and their children into groups which then allow you to limit various aspects of them. Imagine you're running a single physical server for Google with both Maps and GMail having virtual servers on it. If Maps ships an infinite loop bug and it pins the CPU usage of the server to 100%, you only want Maps to go down and _not_ GMail just because it happens to be colocated with Maps. Let's see how to do that.\n\nYou interact with cgroups by a pseudo-file system. Honestly, the whole interface feels weird to me but that is what it is! Inside your #2 terminal (the non-unshared one) run `cd /sys/fs/cgroup` and then run `ls`. You'll see a bunch of \"files\" that look like `cpu.max`, `cgroup.procs`, and `memory.high`. Each one of these represents a setting that you can play with with regard to the cgroup. In this case, we are looking at the root cgroup: all cgroups will be children of this root cgroup. The way you make your own cgroup is by creating a folder inside of the cgroup.\n\n```bash\n# creates the cgroup\nmkdir /sys/fs/cgroup/sandbox\n\n# look at all the files created automatically\nls /sys/fs/cgroup/sandbox\n```\n\nWe now have a sandbox cgroup, which is a child of the root cgroup and can put limits on it! If we wanted to create a child of sandbox, as you may have guessed, just create another folder inside of sandbox.\n\nLet's move our unshared environment into the cgroup. Every process belongs to exactly one cgroup. If you move a process to a cgroup, it will automatically be removed from the cgroup it was in. If we move our unshared bash process from the root cgroup to the sandbox cgroup, it will be removed from the root cgroup without you doing anything.\n\n```bash\n# Find your isolated bash PID, it's the bash one immediately after the unshare\nps aux\n\n# should see the process in the root cgroup\ncat /sys/fs/cgroup/cgroup.procs\n\n# puts the unshared env into the cgroup called sandbox\necho <PID> > /sys/fs/cgroup/sandbox/cgroup.procs\n\n# should see the process in the sandbox cgroup\ncat /sys/fs/cgroup/sandbox/cgroup.procs\n\n# should see the process no longer in the root cgroup - processes belong to exactly 1 cgroup\ncat /sys/fs/cgroup/cgroup.proc\n```\n\nWe now have moved our unshared bash process into a cgroup. We haven't placed any limits on it yet but it's there, ready to be managed. We have a minor problem at the moment though that we need to solve.\n\n```bash\n# should see all the available controllers\ncat /sys/fs/cgroup/cgroup.controllers\n\n# there's no controllers\ncat /sys/fs/cgroup/sandbox/cgroup.controllers\n\n# there's no controllers enabled its children\ncat /sys/fs/cgroup/cgroup.subtree_control\n```\n\nYou have to enable controllers for the children and none of them are enabled at the moment. You can see the root cgroup has them all enabled, but hasn't enabled them in its subtree_control so thus none are available in sandbox's controllers. Easy, right? We just add them to subtree_control, right? Yes, but one problem: you can't add new subtree_control configs while the cgroup itself has processes in it. So we're going to create another cgroup, add the rest of the processes to that one, and then enable the subtree_control configs for the root cgroup.\n\n```bash\n# make new cgroup for the rest of the processes, you can't modify cgroups that have processes and by default Docker doesn't include any subtree_controllers\nmkdir /sys/fs/cgroup/other-procs\n\n# see all the processes you need to move, rerun each time after you add as it may move multiple processes at once due to some being parent / child\ncat /sys/fs/cgroup/cgroup.procs\n\n# you have to do this one at a time for each process\necho <PID> > /sys/fs/cgroup/other-procs/cgroup.procs\n\n# verify all the processes have been moved\ncat /sys/fs/cgroup/cgroup.procs\n\n# add the controllers\necho \"+cpuset +cpu +io +memory +hugetlb +pids +rdma\" > /sys/fs/cgroup/cgroup.subtree_control\n\n# notice how few files there are\nls /sys/fs/cgroup/sandbox\n\n# all the controllers now available\ncat /sys/fs/cgroup/sandbox/cgroup.controllers\n\n# notice how many more files there are now\nls /sys/fs/cgroup/sandbox\n```\n\nWe did it! We went ahead and added all the possible controllers, but normally you should add just the ones you need. If you want to learn more about what each of them does, [the kernel docs are quite readable][kernel].\n\nLet's get a third terminal going. From your host OS (Windows or macOS or your own Linux distro, not within Docker) run another `docker exec -it docker-host bash`. That way, we can have #1 inside the unshared environment, #2 running our commands, and #3 giving us a visual display of what's going with `htop`, a visual tool for seeing what process, CPU cores, and memory are doing.\n\nSo, let's do three little exercises to demonstrate what we can do with a cgroup. First, let's make it so the unshared environment only has access to 80MB of memory instead of all of it.\n\n```bash\n# a cool visual representation of CPU and RAM being used\napt-get install htop\n\n# from #3 so we can watch what's happening\nhtop\n\n# run this from #1 terminal and watch it in htop to see it consume about a gig of RAM and 100% of CPU core\nyes | tr \\\\n x | head -c 1048576000 | grep n\n\n# from #2, (you can get the PID from htop) to stop the CPU from being pegged and memory from being consumed\nkill -9 <PID of yes>\n\n# should see max, so the memory is unlimited\ncat /sys/fs/cgroup/sandbox/memory.max\n\n# set the limit to 80MB of RAM (the number is 80MB in bytes)\necho 83886080 > /sys/fs/cgroup/sandbox/memory.max\n\n# from inside #1, see it limit the RAM taken up; because the RAM is limited, the CPU usage is limited\nyes | tr \\\\n x | head -c 1048576000 | grep n\n```\n\nI think this is very cool. We just made it so our unshared environment only has access to 80MB of RAM, so despite a script being run to literally just consume RAM, it was limited to only consuming 80MB of it.\n\nHowever, as you saw, the user inside of the container could still peg the CPU if they wanted to. Let's fix that. Let's only give them 5% of a core.\n\n```bash\n# inside #1 / the cgroup/unshare â€“ this will peg one core of a CPU at 100% of the resources available, see it peg 1 CPU\nyes > /dev/null\n\n# from #2, (you can get the PID from htop) to stop the CPU from being pegged\nkill -9 <PID of yes>\n\n# from #2 this allows the cgroup to only use 5% of a CPU\necho '5000 100000' > /sys/fs/cgroup/sandbox/cpu.max\n\n# inside #1 / the cgroup/unshare â€“ this will peg one core of a CPU at 5% since we limited it\nyes > /dev/null\n\n# from #2, to stop the CPU from being pegged, get the PID from htop\nkill -9 <PID of yes>\n```\n\nPretty cool, right? Now, no matter how bad the code is we run inside of our chroot'd, unshare'd, cgroup'd environment, we cannot take more than 5% of a CPU core.\n\nOne more demo, the dreaded [fork bomb][fork-bomb]. A fork bomb is a script that forks itself into multiple processes, which then fork themselves, which then fork themselves, etc., until all resources are consumed and it crashes the computer. It can be written plainly as\n\n```bash\nfork() {\n    fork | fork &\n}\nfork\n```\n\nbut you'll see it written as `:(){ :|:& };:` where `:` is the name of the function instead of `fork`.\n\nSo someone could run a fork bomb on our system right now and it'd limit the blast radius of CPU and RAM but creating and destroying so many processes still carries a toll on the system. What we can do to more fully prevent a fork bomb is limit how many PIDs can be active at once. Let's try that.\n\n```bash\n# See how many processes the cgroup has at the moment\ncat /sys/fs/cgroup/sandbox/pids.current\n\n# See how many processes the cgroup can create before being limited (max)\ncat /sys/fs/cgroup/sandbox/pids.max\n\n# set a limit that the cgroup can only run 3 processes at a time\necho 3 > /sys/fs/cgroup/sandbox/pids.max\n\n# this runs 5 15 second processes that run and then stop. run this from within #2 and watch it work. now run it in #1 and watch it not be able to. it will have to retry several times\nfor a in $(seq 1 5); do sleep 15 & done\n\n# DO NOT RUN THIS ON YOUR COMPUTER. This is a fork bomb. If not accounted for, this would bring down your computer. However we can safely run inside our #1 because we've limited the amount of PIDs available. It will end up spawning about 100 processes total but eventually will run out of forks to fork.\n:(){ :|:& };:\n```\n\nAttack prevented! 3 processes is way too few for anyone to do anything meaningful, but by limiting the max PIDs available it allows you to limit what damage could be done. I'll be honest, this is the first time I've run a fork bomb on a computer and it's pretty exhilirating. I felt like I was in the movie _Hackers_. [Hack the planet!][hackers].\n\nAnd now we can call this a container. You have handcrafted a container. A container is literally nothing more than what we did together. There are other sorts of technologies that will accompany containers, like runtimes and daeomons, but the containers themselves are just a combination of chroot, namespaces, and cgroups! Using these features together, we allow Bob, Alice, and Eve to run whatever code they want and the only people they can mess with is themselves.\n\nSo while this is a container at its most basic sense, we haven't broached more advance topics like networking, deploying, bundling, or anything else that something like Docker takes care of for us. But now you know at its most base level what a container is, what it does, and how you _could_ do this yourself, but you'll be grateful that Docker does it for you. On to the next lesson!\n\n[move-to-v2]: https://medium.com/@charles.vissol/cgroup-v2-in-details-8c138088f9ba#aa07\n[v1]: https://btholt.github.io/complete-intro-to-containers/cgroups\n[kernel]: https://docs.kernel.org/admin-guide/cgroup-v2.html#controllers\n[fork-bomb]: https://en.wikipedia.org/wiki/Fork_bomb\n[hackers]: https://youtu.be/Rn2cf_wJ4f4\n","slug":"cgroups","title":"cgroups","section":"Crafting Containers by Hand","icon":"hand-holding-heart","filePath":"/home/runner/work/complete-intro-to-containers-v2/complete-intro-to-containers-v2/lessons/02-crafting-containers-by-hand/D-cgroups.md","nextSlug":"/lessons/docker/docker-images","prevSlug":"/lessons/crafting-containers-by-hand/namespaces"}},"__N_SSG":true}